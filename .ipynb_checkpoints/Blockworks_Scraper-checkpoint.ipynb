{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcfdc351",
   "metadata": {},
   "source": [
    "# Blockworks Articles Scraper\n",
    "\n",
    "This script scrapes article headlines, links, and publication dates from the Blockworks website's tokenization section. The scraped data is saved into a CSV file, appending new relevant articles each time the script is run.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Selenium WebDriver**: Install Selenium WebDriver for Python using the following command:\n",
    "   ```bash\n",
    "   pip install selenium\n",
    "   ```\n",
    "2. **BeautifulSoup**: Install BeautifulSoup for parsing HTML using the following command:\n",
    "   ```bash\n",
    "   pip install beautifulsoup4\n",
    "   ```\n",
    "3. **ChromeDriver**: Download ChromeDriver from [chromedriver.chromium.org](https://chromedriver.chromium.org/downloads) and ensure its path is correct in the script.\n",
    "\n",
    "## Script Overview\n",
    "\n",
    "#### *Setup*\n",
    "\n",
    "1. **Path to ChromeDriver**: Ensure the `webdriver_path` variable points to the correct location of your ChromeDriver executable.\n",
    "2. **Selenium WebDriver Initialization**: The script sets up the Selenium WebDriver and opens the target URL.\n",
    "\n",
    "#### *CSV File Handling*\n",
    "\n",
    "1. **Append Mode**: The script opens the CSV file (`blockworks_articles.csv`) in append mode. If the file does not exist, it creates a new one and writes the header row.\n",
    "2. **Avoiding Duplicates**: The script reads existing headlines from the CSV file to avoid duplications when appending new data.\n",
    "\n",
    "#### *Keywords for Filtering Articles*\n",
    "\n",
    "The script filters articles based on the following keywords: `tokenized`, `tokenization`.\n",
    "\n",
    "#### *Closing Cookie Consent*\n",
    "\n",
    "The script includes a function `close_cookie_consent` to close the cookie consent dialog if it appears.\n",
    "\n",
    "#### *Loading More Articles*\n",
    "\n",
    "A bespoke feature unique to the Blockworks site, the script clicks the \"Load more\" button multiple times (adjustable by `num_clicks`) to load additional articles. If you are using a different site other than the one specified, the code will likely fail. \n",
    "\n",
    "#### *Parsing and Scraping*\n",
    "\n",
    "1. **Parsing with BeautifulSoup**: The script parses the loaded page content using BeautifulSoup.\n",
    "2. **Scraping Data**: For each article, the script extracts the headline, link, and publication date, ensuring no duplicates are added.\n",
    "\n",
    "#### *Writing Data to CSV*\n",
    "\n",
    "The script writes the scraped data (headline, link, date) to the CSV file and prints the data to the console.\n",
    "\n",
    "## Running the Script\n",
    "\n",
    "1. Ensure all prerequisites are met.\n",
    "2. Adjust the `webdriver_path` variable to the correct path of your ChromeDriver.\n",
    "3. Run the script as a Jupyter notebook, or using Python:\n",
    "   ```bash\n",
    "   python blockworks_scraper.py\n",
    "   ```\n",
    "4. The script will append new relevant articles to `blockworks_articles.csv`.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca58cb40",
   "metadata": {},
   "source": [
    "#### *Note*: you will have to physically close certain pop-ups to run the code properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6fbc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Path to your ChromeDriver\n",
    "webdriver_path = 'C:/Program Files/chromedriver-win64/chromedriver.exe'  # Ensure this path is correct\n",
    "\n",
    "# Setup Selenium WebDriver\n",
    "service = Service(webdriver_path)\n",
    "options = Options()\n",
    "# options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.get('https://blockworks.co/search')\n",
    "\n",
    "# Open a CSV file to append the scraped data\n",
    "csv_filename = 'blockworks_articles.csv'\n",
    "file_exists = os.path.isfile(csv_filename)\n",
    "csv_file = open(csv_filename, 'a', newline='', encoding='utf-8')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "\n",
    "# Write header only if the file does not already exist\n",
    "if not file_exists:\n",
    "    csv_writer.writerow(['headline', 'link', 'date'])\n",
    "\n",
    "# Read existing headlines to avoid duplicates\n",
    "existing_headlines = set()\n",
    "if file_exists:\n",
    "    with open(csv_filename, 'r', encoding='utf-8') as read_file:\n",
    "        csv_reader = csv.reader(read_file)\n",
    "        next(csv_reader)  # Skip header row\n",
    "        for row in csv_reader:\n",
    "            if row:\n",
    "                existing_headlines.add(row[0])\n",
    "\n",
    "# Function to close cookie consent button\n",
    "def close_cookie_consent():\n",
    "    try:\n",
    "        # Attempt to locate the button by ID\n",
    "        cookie_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, 'wt-cli-settings-btn'))\n",
    "        )\n",
    "    except:\n",
    "        try:\n",
    "            # Attempt to locate the button by class name as a fallback\n",
    "            cookie_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, 'wt-cli-settings-btn'))\n",
    "            )\n",
    "        except:\n",
    "            print(\"Cookie consent button not found.\")\n",
    "            return  # Exit the function if the button is not found\n",
    "\n",
    "    try:\n",
    "        cookie_button.click()\n",
    "        time.sleep(2)  # Wait for the consent dialog to close\n",
    "        print(\"Cookie consent closed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to close cookie consent: {e}\")\n",
    "\n",
    "# Close cookie consent if it appears\n",
    "close_cookie_consent()\n",
    "\n",
    "# Find the search bar and input 'tokeniz'\n",
    "try:\n",
    "    search_bar = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.ID, 'blockworks-search'))  # Use correct ID for the search bar\n",
    "    )\n",
    "    search_bar.send_keys('tokeniz')\n",
    "    search_bar.send_keys(Keys.RETURN)\n",
    "    print(\"Search query submitted.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error locating search bar: {e}\")\n",
    "    driver.quit()\n",
    "    exit()\n",
    "\n",
    "# Load More button click settings\n",
    "num_clicks = 20  # Number of times to click the 'Load More' button\n",
    "\n",
    "for _ in range(num_clicks):\n",
    "    try:\n",
    "        load_more_button = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//button[text()=\"Load More\"]'))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", load_more_button)  # Scroll into view if needed\n",
    "        load_more_button.click()\n",
    "        time.sleep(3)  # Wait for the content to load\n",
    "        print(f\"'Load More' button clicked {_ + 1} times.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred while clicking 'Load More': {e}\")\n",
    "        break\n",
    "\n",
    "# Parse the loaded page content with BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# Locate all article links on the search results page\n",
    "article_links = [a['href'] for a in soup.find_all('a', class_='font-headline flex-grow text-base font-semibold leading-snug hover:text-primary')]\n",
    "\n",
    "# Use a set to store seen links to avoid duplication\n",
    "seen_links = set()\n",
    "\n",
    "# Loop through each article link\n",
    "for relative_url in article_links:\n",
    "    url = 'https://blockworks.co' + relative_url\n",
    "\n",
    "    # Open the article\n",
    "    driver.execute_script(\"window.open(arguments[0], '_blank');\", url)\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    \n",
    "    try:\n",
    "        # Extract the headline\n",
    "        headline_tag = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, 'font-headline'))\n",
    "        )\n",
    "        headline = headline_tag.text.strip()\n",
    "\n",
    "        # Extract the date\n",
    "        date_tag = driver.find_element(By.TAG_NAME, 'time')\n",
    "        date_text = date_tag.text.strip()\n",
    "        \n",
    "        # Print the scraped data to the console\n",
    "        print(f\"Headline: {headline}\")\n",
    "        print(f\"Link: {url}\")\n",
    "        print(f\"Date: {date_text}\")\n",
    "\n",
    "        # Write the data to the CSV file\n",
    "        if headline not in existing_headlines:\n",
    "            csv_writer.writerow([headline, url, date_text])\n",
    "            existing_headlines.add(headline)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching details for article: {e}\")\n",
    "    \n",
    "    # Close the new tab and switch back to the main tab\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "# Close the CSV file and the WebDriver\n",
    "csv_file.close()\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
